{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHVL_R6FQCj_"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrxeKRPZXCuO"
      },
      "source": [
        "## Lendo os arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcSyCEjnPm4P"
      },
      "outputs": [],
      "source": [
        "data_teste = np.loadtxt(\"3x3_teste.txt\")\n",
        "data_treino = np.loadtxt(\"3x3_treino.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2RmyD90W3Af"
      },
      "source": [
        "# Pegando dados de treino e normalizando utilizando Z-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT1dnbI9P1wl"
      },
      "outputs": [],
      "source": [
        "X_teste = data_teste[:, :-1]  # Recursos teste\n",
        "y_teste = data_teste[:, -1]   # Rótulos teste\n",
        "\n",
        "# Calcule a média e o desvio padrão das características no conjunto de teste\n",
        "mean_teste = X_teste.mean(axis=0)\n",
        "std_teste = X_teste.std(axis=0)\n",
        "\n",
        "# Encontre as características com variância zero no conjunto de teste\n",
        "zero_variance_features = np.where(std_teste == 0)[0]\n",
        "\n",
        "# Remova essas características dos conjuntos de teste\n",
        "X_teste = np.delete(X_teste, zero_variance_features, axis=1)\n",
        "\n",
        "# Calcule a média e o desvio padrão novamente após remover as características com variância zero\n",
        "mean_teste = X_teste.mean(axis=0)\n",
        "std_teste = X_teste.std(axis=0)\n",
        "\n",
        "# Normalize o conjunto de teste usando o Z-score\n",
        "X_test_normalized = (X_teste - mean_teste) / std_teste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-qkr1JvW784"
      },
      "source": [
        "# Pegando dados de teste e normalizando utilizando Z-Score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmsI8COFXAvP"
      },
      "outputs": [],
      "source": [
        "X_treino = data_treino[:, :-1] # Recursos treino\n",
        "y_treino = data_treino[:, -1] # Rótulos treino\n",
        "\n",
        "# Calcule a média e o desvio padrão das características no conjunto de treino\n",
        "mean_treino = X_treino.mean(axis=0)\n",
        "std_treino = X_treino.std(axis=0)\n",
        "\n",
        "# Encontre as características com variância zero no conjunto de teste\n",
        "zero_variance_features = np.where(std_treino == 0)[0]\n",
        "\n",
        "# Remova essas características dos conjuntos de teste\n",
        "X_treino = np.delete(X_treino, zero_variance_features, axis=1)\n",
        "\n",
        "# Calcule a média e o desvio padrão novamente após remover as características com variância zero\n",
        "mean_treino = X_treino.mean(axis=0)\n",
        "std_treino = X_treino.std(axis=0)\n",
        "\n",
        "# Normalize o conjunto de treinamento\n",
        "X_train_normalized = (X_treino - mean_treino) / std_treino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3a-Mo0xXR0V"
      },
      "source": [
        "### Importando bibliotecas para análise dos dados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYQvFRUhP2pY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjhjoMOkXF1d"
      },
      "source": [
        "# Classe KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnue9a6BQFF8"
      },
      "outputs": [],
      "source": [
        "class KNN(object):\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "        self.pontos = None\n",
        "        self.rotulos = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.pontos = X\n",
        "        self.rotulos = y\n",
        "\n",
        "    # Distância Euclidiana\n",
        "    @staticmethod\n",
        "    def dist(p,q):\n",
        "        return np.sqrt(np.sum((p-q)**2))\n",
        "\n",
        "    def predict(self, X):\n",
        "        predicoes = []\n",
        "        # para cada instância p de X\n",
        "        for p in X:\n",
        "            # calcular a distância de p para todos os pontos do conjunto de treinamento\n",
        "            #d = [self.dist(p,q) for q in self.pontos]\n",
        "            d = pairwise_distances(self.pontos, p.reshape((1,-1))).flatten()\n",
        "            # retornar os índices em ordem crescente de distância\n",
        "            ds = np.argsort(d)\n",
        "            # pegar apenas os índices dos k-vizinhos mais próximos\n",
        "            knn = ds[:self.k]\n",
        "            # pegar os rótulos dos k-vizinhos mais próximos\n",
        "            rotulos = self.rotulos[knn]\n",
        "            # contar os rótulos dos vizinhos mais próximos\n",
        "            rotulos, cont = np.unique(rotulos, return_counts=True)\n",
        "            # a predição do ponto p é o rótulo majoritário\n",
        "            pred = rotulos[np.argmax(cont)]\n",
        "            predicoes.append(pred)\n",
        "        return np.array(predicoes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vsTIduvXJ2L"
      },
      "source": [
        "### Valores de K para análise dos resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hla09FMgSwjX"
      },
      "outputs": [],
      "source": [
        "k_values = [1,3,5,7,9,11,13,15,17,19]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQuBR-vvQQnq",
        "outputId": "ba909ae9-8593-4441-f469-2ea9b9ffdeb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K = 1, Acurácia: 0.916\n",
            "K = 3, Acurácia: 0.911\n",
            "K = 5, Acurácia: 0.91\n",
            "K = 7, Acurácia: 0.908\n",
            "K = 9, Acurácia: 0.906\n",
            "K = 11, Acurácia: 0.902\n",
            "K = 13, Acurácia: 0.897\n",
            "K = 15, Acurácia: 0.892\n",
            "K = 17, Acurácia: 0.892\n",
            "K = 19, Acurácia: 0.888\n"
          ]
        }
      ],
      "source": [
        "for k in k_values:\n",
        "  knn = KNN(k=k)\n",
        "  knn.fit(X_train_normalized, y_treino)\n",
        "  pred = knn.predict(X_test_normalized)\n",
        "  accuracy = accuracy_score(y_teste, pred)\n",
        "  print(f\"K = {k}, Acurácia: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS14oeyrZwlD"
      },
      "source": [
        "## Separando os conjuntos aleatóriamente em 25%, 50% e 100% dos dados de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhIuKeIKZ3is"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwk0-AW_Z6M2",
        "outputId": "93569f3b-44af-4412-f1f8-d454cb4c55ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K = 1\n",
            "Divisão: 25%, Acurácia: 0.838\n",
            "Divisão: 50%, Acurácia: 0.866\n",
            "Divisão: 100%, Acurácia: 0.916\n",
            "K = 3\n",
            "Divisão: 25%, Acurácia: 0.84\n",
            "Divisão: 50%, Acurácia: 0.872\n",
            "Divisão: 100%, Acurácia: 0.911\n",
            "K = 5\n",
            "Divisão: 25%, Acurácia: 0.846\n",
            "Divisão: 50%, Acurácia: 0.876\n",
            "Divisão: 100%, Acurácia: 0.91\n",
            "K = 7\n",
            "Divisão: 25%, Acurácia: 0.835\n",
            "Divisão: 50%, Acurácia: 0.884\n",
            "Divisão: 100%, Acurácia: 0.908\n",
            "K = 9\n",
            "Divisão: 25%, Acurácia: 0.812\n",
            "Divisão: 50%, Acurácia: 0.879\n",
            "Divisão: 100%, Acurácia: 0.906\n",
            "K = 11\n",
            "Divisão: 25%, Acurácia: 0.802\n",
            "Divisão: 50%, Acurácia: 0.867\n",
            "Divisão: 100%, Acurácia: 0.902\n",
            "K = 13\n",
            "Divisão: 25%, Acurácia: 0.806\n",
            "Divisão: 50%, Acurácia: 0.865\n",
            "Divisão: 100%, Acurácia: 0.897\n",
            "K = 15\n",
            "Divisão: 25%, Acurácia: 0.797\n",
            "Divisão: 50%, Acurácia: 0.855\n",
            "Divisão: 100%, Acurácia: 0.892\n",
            "K = 17\n",
            "Divisão: 25%, Acurácia: 0.805\n",
            "Divisão: 50%, Acurácia: 0.845\n",
            "Divisão: 100%, Acurácia: 0.892\n",
            "K = 19\n",
            "Divisão: 25%, Acurácia: 0.792\n",
            "Divisão: 50%, Acurácia: 0.844\n",
            "Divisão: 100%, Acurácia: 0.888\n"
          ]
        }
      ],
      "source": [
        "# Dividir o conjunto de treinamento em diferentes proporções\n",
        "X_train_25, X_unused, y_train_25, y_unused = train_test_split(X_train_normalized, y_treino, test_size=0.75, random_state=42)\n",
        "X_train_50, X_unused, y_train_50, y_unused = train_test_split(X_train_normalized, y_treino, test_size=0.5, random_state=42)\n",
        "X_train_100 = X_train_normalized\n",
        "y_train_100 = y_treino\n",
        "\n",
        "# Treinar e avaliar o modelo KNN com diferentes divisões\n",
        "for k in k_values:\n",
        "  print(f\"K = {k}\")\n",
        "  for X_train, y_train, label in [(X_train_25, y_train_25, '25%'), (X_train_50, y_train_50, '50%'), (X_train_100, y_train_100, '100%')]:\n",
        "      knn = KNN(k=k)\n",
        "      knn.fit(X_train, y_train)\n",
        "      pred = knn.predict(X_test_normalized)\n",
        "      accuracy = accuracy_score(y_teste, pred)\n",
        "      print(f\"Divisão: {label}, Acurácia: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
